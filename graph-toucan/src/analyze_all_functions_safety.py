"""
å…¨é¢åˆ†æ generated_functions_v1 ç›®å½•ä¸‹æ‰€æœ‰å‡½æ•°
è¯„ä¼° SafeExecutionContext çš„ä¿æŠ¤èƒ½åŠ›
"""
import os
import ast
from pathlib import Path
from collections import defaultdict
import json


GENERATED_FUNCTIONS_DIR = "/data/lhy/datasets/graph-Toucan/tool_info/generated_functions_v1"


class FunctionAnalyzer:
    """åˆ†æå‡½æ•°ä½¿ç”¨çš„æ“ä½œ"""

    def __init__(self):
        self.stats = {
            'total_files': 0,
            'analyzed_files': 0,
            'error_files': 0,

            # æ–‡ä»¶æ“ä½œ
            'uses_open': [],
            'uses_pathlib': [],
            'uses_file_operations': [],

            # æ¨¡å—å¯¼å…¥
            'imports_os': [],
            'imports_sys': [],
            'imports_subprocess': [],
            'imports_pathlib': [],
            'imports_shutil': [],

            # å±é™©å‡½æ•°è°ƒç”¨
            'calls_eval': [],
            'calls_exec': [],
            'calls_compile': [],
            'calls_subprocess': [],
            'calls_os_system': [],
            'calls_os_chdir': [],
            'calls_os_listdir': [],
            'calls_os_walk': [],

            # pathlib æ“ä½œ
            'pathlib_read': [],
            'pathlib_write': [],
            'pathlib_unlink': [],
        }

    def analyze_file(self, file_path: str) -> dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content, filename=file_path)
            file_name = os.path.basename(file_path)

            # æ£€æŸ¥å¯¼å…¥
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        module_name = alias.name
                        if module_name == 'os' or module_name.startswith('os.'):
                            self.stats['imports_os'].append(file_name)
                        elif module_name == 'sys':
                            self.stats['imports_sys'].append(file_name)
                        elif module_name == 'subprocess':
                            self.stats['imports_subprocess'].append(file_name)
                        elif module_name == 'pathlib':
                            self.stats['imports_pathlib'].append(file_name)
                        elif module_name == 'shutil':
                            self.stats['imports_shutil'].append(file_name)

                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        if node.module == 'os' or node.module.startswith('os.'):
                            self.stats['imports_os'].append(file_name)
                        elif node.module == 'pathlib':
                            self.stats['imports_pathlib'].append(file_name)
                            # æ£€æŸ¥å¯¼å…¥çš„å…·ä½“å†…å®¹
                            for alias in node.names:
                                if alias.name == 'Path':
                                    self.stats['uses_pathlib'].append(file_name)
                        elif node.module == 'subprocess':
                            self.stats['imports_subprocess'].append(file_name)
                        elif node.module == 'shutil':
                            self.stats['imports_shutil'].append(file_name)

                # æ£€æŸ¥å‡½æ•°è°ƒç”¨
                elif isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name):
                        func_name = node.func.id

                        if func_name == 'open':
                            self.stats['uses_open'].append(file_name)
                        elif func_name == 'eval':
                            self.stats['calls_eval'].append(file_name)
                        elif func_name == 'exec':
                            self.stats['calls_exec'].append(file_name)
                        elif func_name == 'compile':
                            self.stats['calls_compile'].append(file_name)

                    elif isinstance(node.func, ast.Attribute):
                        # æ£€æŸ¥ os.xxx() è°ƒç”¨
                        if isinstance(node.func.value, ast.Name):
                            if node.func.value.id == 'os':
                                attr = node.func.attr
                                if attr == 'system':
                                    self.stats['calls_os_system'].append(file_name)
                                elif attr == 'chdir':
                                    self.stats['calls_os_chdir'].append(file_name)
                                elif attr in ['listdir', 'scandir']:
                                    self.stats['calls_os_listdir'].append(file_name)
                                elif attr == 'walk':
                                    self.stats['calls_os_walk'].append(file_name)

                        # æ£€æŸ¥ subprocess.xxx() è°ƒç”¨
                        if isinstance(node.func.value, ast.Name):
                            if node.func.value.id == 'subprocess':
                                self.stats['calls_subprocess'].append(file_name)

                        # æ£€æŸ¥ pathlib æ“ä½œ
                        if node.func.attr in ['read_text', 'read_bytes']:
                            self.stats['pathlib_read'].append(file_name)
                        elif node.func.attr in ['write_text', 'write_bytes']:
                            self.stats['pathlib_write'].append(file_name)
                        elif node.func.attr == 'unlink':
                            self.stats['pathlib_unlink'].append(file_name)

            return {'status': 'success', 'file': file_name}

        except Exception as e:
            return {'status': 'error', 'file': os.path.basename(file_path), 'error': str(e)}

    def analyze_directory(self, directory: str):
        """åˆ†ææ•´ä¸ªç›®å½•"""
        py_files = sorted(Path(directory).glob("*.py"))
        self.stats['total_files'] = len(py_files)

        print(f"å¼€å§‹åˆ†æ {len(py_files)} ä¸ªæ–‡ä»¶...")

        for i, py_file in enumerate(py_files):
            if (i + 1) % 100 == 0:
                print(f"  è¿›åº¦: {i + 1}/{len(py_files)}")

            result = self.analyze_file(str(py_file))
            if result['status'] == 'success':
                self.stats['analyzed_files'] += 1
            else:
                self.stats['error_files'] += 1

        print(f"âœ… åˆ†æå®Œæˆï¼")

    def get_report(self) -> dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        # å»é‡
        for key in self.stats:
            if isinstance(self.stats[key], list):
                self.stats[key] = list(set(self.stats[key]))

        return self.stats


def evaluate_safe_execution_context(stats: dict):
    """è¯„ä¼° SafeExecutionContext çš„ä¿æŠ¤èƒ½åŠ›"""

    print("\n" + "="*70)
    print("SafeExecutionContext ä¿æŠ¤èƒ½åŠ›è¯„ä¼°")
    print("="*70)

    total_files = stats['total_files']

    # 1. ç»Ÿè®¡å¯è¢«ä¿æŠ¤çš„æ–‡ä»¶
    protected_operations = {
        'open()': stats['uses_open'],
        'os module imports': stats['imports_os'],
        'sys module imports': stats['imports_sys'],
        'eval': stats['calls_eval'],
        'exec': stats['calls_exec'],
        'subprocess': stats['calls_subprocess'],
    }

    # 2. ç»Ÿè®¡å¯èƒ½ç»•è¿‡çš„æ–‡ä»¶
    bypass_operations = {
        'pathlib usage': stats['uses_pathlib'] + stats['imports_pathlib'],
        'os.chdir': stats['calls_os_chdir'],
        'os.listdir/walk': stats['calls_os_listdir'] + stats['calls_os_walk'],
        'os.system': stats['calls_os_system'],
        'pathlib read': stats['pathlib_read'],
        'pathlib write': stats['pathlib_write'],
    }

    print("\nâœ… SafeExecutionContext èƒ½å¤Ÿä¿æŠ¤çš„æ“ä½œï¼š\n")
    protected_files = set()
    for op_name, files in protected_operations.items():
        files = list(set(files))
        if files:
            print(f"  {op_name}: {len(files)} ä¸ªæ–‡ä»¶")
            protected_files.update(files)

    print(f"\n  æ€»è®¡è¢«ä¿æŠ¤çš„æ–‡ä»¶: {len(protected_files)} ä¸ª")

    print("\nâŒ SafeExecutionContext æ— æ³•ä¿æŠ¤çš„æ“ä½œï¼ˆå¯èƒ½è¢«ç»•è¿‡ï¼‰ï¼š\n")
    vulnerable_files = set()
    for op_name, files in bypass_operations.items():
        files = list(set(files))
        if files:
            print(f"  {op_name}: {len(files)} ä¸ªæ–‡ä»¶")
            vulnerable_files.update(files)

    print(f"\n  æ€»è®¡æœ‰æ¼æ´çš„æ–‡ä»¶: {len(vulnerable_files)} ä¸ª")

    # 3. ç»Ÿè®¡å®Œå…¨å®‰å…¨çš„æ–‡ä»¶
    all_risky_files = protected_files | vulnerable_files
    safe_files = total_files - len(all_risky_files)

    print("\n" + "="*70)
    print("æ€»ä½“ç»Ÿè®¡")
    print("="*70)

    print(f"\næ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"  ğŸŸ¢ å®Œå…¨ä¸å«ä»»ä½•å±é™©æ“ä½œ: {safe_files} ({safe_files/total_files*100:.1f}%)")
    print(f"  âœ… ä½¿ç”¨å±é™©æ“ä½œä½†è¢«ä¿æŠ¤: {len(protected_files - vulnerable_files)} ({len(protected_files - vulnerable_files)/total_files*100:.1f}%)")
    print(f"  âš ï¸  ä½¿ç”¨å±é™©æ“ä½œä¸”éƒ¨åˆ†å¯ç»•è¿‡: {len(protected_files & vulnerable_files)} ({len(protected_files & vulnerable_files)/total_files*100:.1f}%)")
    print(f"  âŒ ä½¿ç”¨å±é™©æ“ä½œä¸”å®Œå…¨å¯ç»•è¿‡: {len(vulnerable_files - protected_files)} ({len(vulnerable_files - protected_files)/total_files*100:.1f}%)")

    # 4. é£é™©è¯„ä¼°
    print("\n" + "="*70)
    print("é£é™©ç­‰çº§åˆ†ç±»")
    print("="*70)

    # é«˜é£é™©ï¼šä½¿ç”¨ pathlib æˆ– os.chdir
    high_risk = set(stats['uses_pathlib']) | set(stats['imports_pathlib']) | set(stats['calls_os_chdir'])

    # ä¸­é£é™©ï¼šä½¿ç”¨ os.listdir/walk æˆ– os.system
    medium_risk = (set(stats['calls_os_listdir']) | set(stats['calls_os_walk']) |
                   set(stats['calls_os_system'])) - high_risk

    # ä½é£é™©ï¼šä»…ä½¿ç”¨ open() å’Œå¯¼å…¥ os/sys
    low_risk = (set(stats['uses_open']) | set(stats['imports_os']) |
                set(stats['imports_sys'])) - high_risk - medium_risk

    print(f"\nğŸ”´ é«˜é£é™©ï¼ˆpathlib/os.chdirï¼‰: {len(high_risk)} ä¸ªæ–‡ä»¶")
    if high_risk:
        print("   è¿™äº›æ–‡ä»¶å¯ä»¥å®Œå…¨ç»•è¿‡ SafeExecutionContext")
        for f in sorted(list(high_risk))[:10]:
            print(f"     - {f}")
        if len(high_risk) > 10:
            print(f"     ... è¿˜æœ‰ {len(high_risk) - 10} ä¸ª")

    print(f"\nğŸŸ  ä¸­é£é™©ï¼ˆos.listdir/walk/systemï¼‰: {len(medium_risk)} ä¸ªæ–‡ä»¶")
    if medium_risk:
        print("   è¿™äº›æ–‡ä»¶å¯ä»¥æ³„éœ²ä¿¡æ¯æˆ–æ‰§è¡Œå‘½ä»¤")
        for f in sorted(list(medium_risk))[:5]:
            print(f"     - {f}")
        if len(medium_risk) > 5:
            print(f"     ... è¿˜æœ‰ {len(medium_risk) - 5} ä¸ª")

    print(f"\nğŸŸ¡ ä½é£é™©ï¼ˆopen/import os/sysï¼‰: {len(low_risk)} ä¸ªæ–‡ä»¶")
    print("   è¿™äº›æ–‡ä»¶è¢« SafeExecutionContext æœ‰æ•ˆä¿æŠ¤")

    print(f"\nğŸŸ¢ æ— é£é™©: {safe_files} ä¸ªæ–‡ä»¶")
    print("   è¿™äº›æ–‡ä»¶ä¸å«ä»»ä½•å±é™©æ“ä½œ")

    # 5. æœ€ç»ˆè¯„ä¼°
    print("\n" + "="*70)
    print("æœ€ç»ˆè¯„ä¼°")
    print("="*70)

    total_protected = safe_files + len(low_risk)
    total_vulnerable = len(high_risk) + len(medium_risk)

    print(f"\nâœ… å®‰å…¨/è¢«ä¿æŠ¤: {total_protected}/{total_files} ({total_protected/total_files*100:.1f}%)")
    print(f"âŒ æœ‰æ¼æ´: {total_vulnerable}/{total_files} ({total_vulnerable/total_files*100:.1f}%)")

    if total_vulnerable / total_files > 0.1:
        print(f"\nâš ï¸  è­¦å‘Š: {total_vulnerable/total_files*100:.1f}% çš„æ–‡ä»¶å­˜åœ¨å®‰å…¨æ¼æ´")
        print("   SafeExecutionContext ä¸è¶³ä»¥ä¿æŠ¤è¿™äº›æ–‡ä»¶")
        print("   å»ºè®®ï¼š")
        print("     1. å¢å¼º SafeExecutionContextï¼ˆé™åˆ¶ pathlib, os.chdir ç­‰ï¼‰")
        print("     2. ä½¿ç”¨ Docker æ²™ç®±")
        print("     3. é‡æ–°ç”Ÿæˆé«˜é£é™©å‡½æ•°ï¼Œç§»é™¤å±é™©æ“ä½œ")
    elif total_vulnerable / total_files > 0.05:
        print(f"\nâš ï¸  æ³¨æ„: {total_vulnerable/total_files*100:.1f}% çš„æ–‡ä»¶å­˜åœ¨å®‰å…¨æ¼æ´")
        print("   SafeExecutionContext åŸºæœ¬å¤Ÿç”¨ï¼Œä½†å»ºè®®å¢å¼º")
    else:
        print(f"\nâœ… è‰¯å¥½: åªæœ‰ {total_vulnerable/total_files*100:.1f}% çš„æ–‡ä»¶å­˜åœ¨æ¼æ´")
        print("   SafeExecutionContext åŸºæœ¬æ»¡è¶³éœ€æ±‚")

    # ä¿å­˜è¯¦ç»†ç»“æœ
    with open('/data/lhy/datasets/graph-Toucan/tool_info/safe_execution_analysis.json', 'w') as f:
        json.dump({
            'total_files': total_files,
            'safe_files': safe_files,
            'high_risk_files': sorted(list(high_risk)),
            'medium_risk_files': sorted(list(medium_risk)),
            'low_risk_files': sorted(list(low_risk)),
            'statistics': {
                'protected': total_protected,
                'vulnerable': total_vulnerable,
                'protection_rate': total_protected / total_files,
            }
        }, f, indent=2)

    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: tool_info/safe_execution_analysis.json")


def main():
    print("="*70)
    print("åˆ†ææ‰€æœ‰å‡½æ•°å¯¹ SafeExecutionContext çš„ä¾èµ–")
    print("="*70)
    print()

    analyzer = FunctionAnalyzer()
    analyzer.analyze_directory(GENERATED_FUNCTIONS_DIR)

    stats = analyzer.get_report()
    evaluate_safe_execution_context(stats)


if __name__ == "__main__":
    main()
