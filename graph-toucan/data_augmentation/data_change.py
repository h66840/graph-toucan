import random
import json
import ast
import copy
import datasets



def check_and_fix_format(data):
    """
    æ£€æŸ¥å’Œä¿®å¤æ•°æ®æ ¼å¼ï¼š
    1. ç¡®ä¿toolså­—æ®µæ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²
    2. ç¡®ä¿messagesä¸­roleä¸º'tool_call', 'tool_response', 'tool'çš„contentéƒ½æ˜¯JSONå­—ç¬¦ä¸²
    """
    # 1. æ£€æŸ¥å’Œä¿®å¤toolså­—æ®µ
    if 'tools' in data and data['tools']:
        
        assert type(data['tools']) == str
        # å°è¯•è§£ætoolsï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ™éªŒè¯ï¼Œå¦‚æœä¸æ˜¯åˆ™è½¬æ¢
        if isinstance(data['tools'], str):
            tools_obj = json.loads(data['tools'])
            # é‡æ–°åºåˆ—åŒ–ä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®
            data['tools'] = json.dumps(tools_obj, ensure_ascii=False)
        else:
            # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            data['tools'] = json.dumps(data['tools'], ensure_ascii=False)

            

    # 2. æ£€æŸ¥å’Œä¿®å¤messageså­—æ®µ
    if 'messages' in data and data['messages']:
        try:
            # è§£æmessages
            if isinstance(data['messages'], str):
                messages = json.loads(data['messages'])
            else:
                messages = data['messages']
            assert type(messages) == list
            # æ£€æŸ¥æ¯ä¸ªæ¶ˆæ¯çš„contentå­—æ®µ
            modified = False
            for msg in messages:
                if msg.get('role') in ['tool_call', 'tool_response', 'tool']:
                    content = msg.get('content', '')
                    if content:
                        assert type(content) == str
                        # æ£€æŸ¥contentæ˜¯å¦æ˜¯JSONå­—ç¬¦ä¸²
                        if isinstance(content, str):
                            try:
                                # å°è¯•è§£æä»¥éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²
                                json.loads(content)
                                # å¦‚æœæˆåŠŸè§£æï¼Œè¯´æ˜å·²ç»æ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²ï¼Œä¸éœ€è¦ä¿®æ”¹
                            except (json.JSONDecodeError, ValueError):
                                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç”¨ast.literal_eval
                                try:
                                    
                                    content_obj = ast.literal_eval(content)
                                    assert type(content_obj) == dict
                                    msg['content'] = json.dumps(content_obj, ensure_ascii=False)
                                    modified = True
                                except:
                                    # å¦‚æœéƒ½å¤±è´¥ï¼Œè¯´æ˜æ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼Œå°†å…¶åŒ…è£…æˆJSONå­—ç¬¦ä¸²
                                    # è¿™é‡Œå°†æ™®é€šå­—ç¬¦ä¸²æœ¬èº«ä½œä¸ºå€¼è¿›è¡ŒJSONç¼–ç 
                                    msg['content'] = json.dumps(content, ensure_ascii=False)
                                    modified = True
                                    
                                    
                        else:
                            # å¦‚æœcontentä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                            msg['content'] = json.dumps(content, ensure_ascii=False)
                            modified = True
                            assert 0
            # å¦‚æœä¿®æ”¹äº†messagesï¼Œæ›´æ–°data
            assert type(messages) == list

            data['messages'] = json.dumps(messages)

        except Exception as e:
            print(f"Warning: messageså­—æ®µæ ¼å¼å¼‚å¸¸: {e}")
            assert 0
            return data

    return data


def process_single_sample(data):
    
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œéšæœºä¿®æ”¹æŸä¸ªturnçš„æ•°æ®
    """
    # åˆå§‹åŒ–æ–°å­—æ®µ
    data['is_modified'] = False
    data['modification_info'] = ""  # ç”¨ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºNoneï¼Œå› ä¸ºdatasetsä¸æ”¯æŒNoneä½œä¸ºåˆ—å€¼
    
    if data['subset_name'] not in ['multi-turn']:
        return data

    # éšæœºæŠ½æ ·30%è¿›è¡Œå¤„ç†
    if random.random() > 0.3:
        return data

    messages = data['messages']
    # format the message
    assert type(messages) == str
    messages = json.loads(messages)
    assert type(messages) == list

    # æ‰¾åˆ°æ‰€æœ‰useræ¶ˆæ¯çš„ä½ç½®ï¼ˆturnçš„å¼€å§‹ï¼‰
    user_positions = []
    for i, msg in enumerate(messages):
        if msg['role'] == 'user':
            user_positions.append(i)

    if not user_positions:
        return data  # å¦‚æœæ²¡æœ‰useræ¶ˆæ¯ï¼Œè·³è¿‡

    # éšæœºé€‰æ‹©ä¸€ä¸ªturn
    selected_turn_start = random.choice(user_positions)

    # ç¡®å®šè¿™æ˜¯ç¬¬å‡ è½®ï¼ˆä»0å¼€å§‹è®¡æ•°ï¼‰
    turn_number = user_positions.index(selected_turn_start)

    # ç¡®å®šè¿™ä¸ªturnçš„ç»“æŸä½ç½®
    turn_end = len(messages)
    for pos in user_positions:
        if pos > selected_turn_start:
            turn_end = pos
            break

    # ä¿®æ”¹è¿™ä¸ªturnä¸­çš„æŸäº›æ¶ˆæ¯
    # 1. æ”¶é›†å½“å‰turnä¸­æ‰€æœ‰çš„tool_call
    turn_tool_calls = []
    for i in range(selected_turn_start, turn_end):
        msg = messages[i]
        if msg['role'] == 'tool_call':
            # è§£æcontentè·å–toolåç§°
            try:
                tool_info = ast.literal_eval(msg['content'])
                tool_name = tool_info.get('name')
                if tool_name:
                    turn_tool_calls.append({
                        'msg_index': i,
                        'tool_name': tool_name,
                        'msg': msg
                    })
            except:
                assert 0

    # å¦‚æœå½“å‰turnæ²¡æœ‰tool_callï¼Œè·³è¿‡
    if not turn_tool_calls:
        return data

    # 2. æ”¶é›†ä¹‹å‰æ‰€æœ‰turnä¸­è°ƒç”¨è¿‡çš„tool
    previous_tools = set()
    for i in range(0, selected_turn_start):
        msg = messages[i]
        if msg['role'] == 'tool_call':
            try:
                tool_info = ast.literal_eval(msg['content'])
                tool_name = tool_info.get('name')
                if tool_name:
                    previous_tools.add(tool_name)
            except:
                assert 0

    # 3. æ‰¾åˆ°ä¸€ä¸ªåœ¨ä¹‹å‰æ²¡æœ‰è°ƒç”¨è¿‡çš„tool_call
    available_tool_calls = [tc for tc in turn_tool_calls if tc['tool_name'] not in previous_tools]

    # å¦‚æœæ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„tool_callï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
    if not available_tool_calls:
        return data

    # éšæœºé€‰æ‹©ä¸€ä¸ªæœªåœ¨ä¹‹å‰è°ƒç”¨è¿‡çš„tool_call
    selected_tool_call = random.choice(available_tool_calls)
    selected_tool_name = selected_tool_call['tool_name']

    # 4. ä»toolså­—æ®µä¸­æ‰¾åˆ°å¹¶popå‡ºè¿™ä¸ªtoolçš„ä¿¡æ¯
    tools_list = json.loads(data['tools'])
    removed_tool = None
    new_tools_list = []

    for tool in tools_list:
        if tool.get('type') == 'function' and tool['function']['name'] == selected_tool_name:
            removed_tool = tool
        else:
            new_tools_list.append(tool)

    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„toolå®šä¹‰ï¼Œè·³è¿‡
    if removed_tool is None:
        return data

    # add meta info
    data['is_modified'] = True
    data['modification_info'] = json.dumps({
        'modified_turn_index': selected_turn_start,
        'turn_number': turn_number,  # ç¬¬å‡ è½®ï¼ˆä»0å¼€å§‹è®¡æ•°ï¼‰
        'total_turns': len(user_positions),  # æ€»å…±æœ‰å¤šå°‘è½®
        'removed_tool_name': selected_tool_name,
        'removed_tool_definition': removed_tool,
    }, ensure_ascii=False)

    # æ›´æ–°toolså­—æ®µ
    data['tools'] = json.dumps(new_tools_list)

    # 5. æ„é€ æ–°çš„æ¶ˆæ¯åºåˆ—ï¼šå°†è¿™ä¸€è½®åˆ†ä¸º(a, b)ä¸¤éƒ¨åˆ†
    # a: ç¬¬ä¸€ä¸ªturn - å›å¤è¯´ä¿¡æ¯ä¸è¶³
    # b: ç¬¬äºŒä¸ªturn - æä¾›ç¼ºå¤±çš„å‡½æ•°ä¿¡æ¯ï¼Œç„¶åç»§ç»­åŸæ¥çš„æ“ä½œ

    # è·å–åŸå§‹useræ¶ˆæ¯
    original_user_msg = messages[selected_turn_start]

    # æ„é€ æ–°çš„æ¶ˆæ¯åˆ—è¡¨
    new_messages = []

    # ä¿ç•™ä¹‹å‰çš„æ‰€æœ‰æ¶ˆæ¯
    new_messages.extend(messages[:selected_turn_start])

    # æ·»åŠ ç¬¬ä¸€ä¸ªturn (a): useræ¶ˆæ¯ + assistantå›å¤ä¿¡æ¯ä¸è¶³
    new_messages.append(copy.deepcopy(original_user_msg))
    new_messages.append({
        'role': 'assistant',
        'content': "Sorry, I don't have enough information to answer the request. I'm missing some necessary tools to complete this task."
    })

    # æ·»åŠ ç¬¬äºŒä¸ªturn (b): æä¾›å·¥å…·ä¿¡æ¯çš„useræ¶ˆæ¯ + åŸturnçš„æ‰€æœ‰æ¶ˆæ¯
    tool_info_message = {
        'role': 'user',
        'content': f"Here is the additional tool you can use now: {json.dumps(removed_tool, ensure_ascii=False)}"
    }
    new_messages.append(tool_info_message)

    # æ·»åŠ åŸturnä¸­é™¤äº†useræ¶ˆæ¯ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆassistantå›å¤ã€tool_callç­‰ï¼‰
    new_messages.extend(messages[selected_turn_start + 1:turn_end])

    # æ·»åŠ è¿™ä¸ªturnä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
    new_messages.extend(messages[turn_end:])

    # æ›´æ–°dataçš„messagesï¼ˆéœ€è¦è½¬å›jsonå­—ç¬¦ä¸²ï¼‰
    data['messages'] = json.dumps(new_messages, ensure_ascii=False)

    return data



def process_single_sample_v2(data):
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œæ‰¾åˆ°æ¯ä¸ªå‡½æ•°ç¬¬ä¸€æ¬¡å‡ºç°çš„ä½ç½®ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªæ¥ä¿®æ”¹
    è¿™æ ·å¯ä»¥ä¿è¯æ¯ä¸ªé€‰ä¸­çš„sampleéƒ½ä¼šè¢«ä¿®æ”¹ï¼Œä¸ä¼šskip
    # todo
    åŠ å…¥ç¬¬ä¸€æ¬¡å‡ºç°çš„å‡½æ•°é›†åˆï¼ˆåœ¨éšæœºæŠ½æ ·ä¹‹å‰ï¼‰ä½¿ç”¨user message indexåšåˆ‡åˆ†ä»¥åçš„æ¦‚ç‡åˆ†å¸ƒ
    å…ˆåˆ‡æˆä¸¤ç±»ï¼ˆç¬¬ä¸€è½®(user_messages[0]<func_index<user_messages[1])å’Œå…¶ä»–è½®ï¼‰.
    æŒ‰ç…§åæ¯”å…³ç³»åŠ¨æ€è°ƒæ•´æ¯ä¸€ç±»çš„æŠ½æ ·æ¦‚ç‡ã€‚
    """
    # åˆå§‹åŒ–æ–°å­—æ®µ
    data['is_modified'] = False
    data['modification_info'] = ""  # ç”¨ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºNoneï¼Œå› ä¸ºdatasetsä¸æ”¯æŒNoneä½œä¸ºåˆ—å€¼

    if data['subset_name'] not in ['multi-turn','single-turn-original']:
        return data

    

    messages = data['messages']
    # format the message
    assert type(messages) == str
    messages = json.loads(messages)
    assert type(messages) == list

    # 0. å…ˆæ”¶é›†æ‰€æœ‰ user message çš„ä½ç½®ï¼Œç”¨äºç¡®å®šè½®æ¬¡
    user_positions = []
    for i, msg in enumerate(messages):
        if msg['role'] == 'user':
            user_positions.append(i)

    if not user_positions:
        return data  # å¦‚æœæ²¡æœ‰useræ¶ˆæ¯ï¼Œè·³è¿‡

    # 1. æ‰¾åˆ°æ¯ä¸ªå‡½æ•°ç¬¬ä¸€æ¬¡å‡ºç°çš„ä½ç½®
    first_appearance = {}  # {tool_name: {'index': msg_index, 'msg': msg}}

    for i, msg in enumerate(messages):
        if msg['role'] == 'tool_call':
            try:
                tool_info = json.loads(msg['content'])
                tool_name = tool_info.get('name')
                if tool_name and tool_name not in first_appearance:
                    first_appearance[tool_name] = {
                        'index': i,
                        'tool_name': tool_name,
                        'msg': msg
                    }
            except:
                try:
                    tool_info = ast.literal_eval(msg['content'])
                    tool_name = tool_info.get('name')
                    if tool_name and tool_name not in first_appearance:
                        first_appearance[tool_name] = {
                            'index': i,
                            'tool_name': tool_name,
                            'msg': msg
                        }
                except:
                    assert 0

    # å¦‚æœæ²¡æœ‰tool_callï¼Œè·³è¿‡
    if not first_appearance:
        return data
    
    # 2. éšæœºé€‰æ‹©ä¸€ä¸ªç¬¬ä¸€æ¬¡å‡ºç°çš„å‡½æ•°
    selected_tool_info = random.choice(list(first_appearance.values()))
    selected_tool_name = selected_tool_info['tool_name']
    selected_tool_index = selected_tool_info['index']

    # 3. å¾€å‰æ‰¾åˆ°ç¦»è¿™ä¸ªå‡½æ•°æœ€è¿‘çš„user messageçš„index
    selected_turn_start = None
    for i in range(selected_tool_index, -1, -1):
        if messages[i]['role'] == 'user':
            selected_turn_start = i
            break

    # å¦‚æœæ‰¾ä¸åˆ°useræ¶ˆæ¯ï¼Œè·³è¿‡
    if selected_turn_start is None:
        return data

    # ç¡®å®šè¿™æ˜¯ç¬¬å‡ è½®ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰
    turn_number = user_positions.index(selected_turn_start)

    # 4. ç¡®å®šè¿™ä¸ªturnçš„ç»“æŸä½ç½®
    turn_end = len(messages)
    for i in range(selected_turn_start + 1, len(messages)):
        if messages[i]['role'] == 'user':
            turn_end = i
            break

    # 5. ä»toolså­—æ®µä¸­æ‰¾åˆ°å¹¶popå‡ºè¿™ä¸ªtoolçš„ä¿¡æ¯
    tools_list = json.loads(data['tools'])
    removed_tool = None
    new_tools_list = []

    for tool in tools_list:
        if tool.get('type') == 'function' and tool['function']['name'] == selected_tool_name:
            removed_tool = tool
        else:
            new_tools_list.append(tool)

    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„toolå®šä¹‰ï¼Œè·³è¿‡
    if removed_tool is None:
        return data

    # add meta info
    data['is_modified'] = True
    data['modification_info'] = json.dumps({
        'modified_turn_index': selected_turn_start,
        'turn_number': turn_number,  # ç¬¬å‡ è½®ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰
        'total_turns': len(user_positions),  # æ€»å…±æœ‰å¤šå°‘è½®
        'removed_tool_name': selected_tool_name,
        'removed_tool_definition': removed_tool,
    }, ensure_ascii=False)

    # æ›´æ–°toolså­—æ®µ
    data['tools'] = json.dumps(new_tools_list, ensure_ascii=False)

    # 6. æ„é€ æ–°çš„æ¶ˆæ¯åºåˆ—ï¼šå°†è¿™ä¸€è½®åˆ†ä¸º(a, b)ä¸¤éƒ¨åˆ†
    # a: ç¬¬ä¸€ä¸ªturn - å›å¤è¯´ä¿¡æ¯ä¸è¶³
    # b: ç¬¬äºŒä¸ªturn - æä¾›ç¼ºå¤±çš„å‡½æ•°ä¿¡æ¯ï¼Œç„¶åç»§ç»­åŸæ¥çš„æ“ä½œ

    # è·å–åŸå§‹useræ¶ˆæ¯
    original_user_msg = messages[selected_turn_start]

    # æ„é€ æ–°çš„æ¶ˆæ¯åˆ—è¡¨
    new_messages = []

    # ä¿ç•™ä¹‹å‰çš„æ‰€æœ‰æ¶ˆæ¯
    new_messages.extend(messages[:selected_turn_start])

    # æ·»åŠ ç¬¬ä¸€ä¸ªturn (a): useræ¶ˆæ¯ + assistantå›å¤ä¿¡æ¯ä¸è¶³
    new_messages.append(copy.deepcopy(original_user_msg))
    new_messages.append({
        'role': 'assistant',
        'content': "Sorry, I don't have enough information to answer the request. I'm missing some necessary tools to complete this task."
    })

    # æ·»åŠ ç¬¬äºŒä¸ªturn (b): æä¾›å·¥å…·ä¿¡æ¯çš„useræ¶ˆæ¯ + åŸturnçš„æ‰€æœ‰æ¶ˆæ¯
    tool_info_message = {
        'role': 'user',
        'content': f"Here is the additional tool you can use now: {json.dumps(removed_tool, ensure_ascii=False)}"
    }
    new_messages.append(tool_info_message)

    # æ·»åŠ åŸturnä¸­é™¤äº†useræ¶ˆæ¯ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆassistantå›å¤ã€tool_callç­‰ï¼‰
    new_messages.extend(messages[selected_turn_start + 1:turn_end])

    # æ·»åŠ è¿™ä¸ªturnä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
    new_messages.extend(messages[turn_end:])

    # æ›´æ–°dataçš„messagesï¼ˆéœ€è¦è½¬å›jsonå­—ç¬¦ä¸²ï¼‰
    data['messages'] = json.dumps(new_messages, ensure_ascii=False)

    return data


def _select_tool_with_turn_bias(first_appearance, messages, user_positions, 
                                  bias_factor=2.0, min_prob=0,max_prob=0):
    """
    ğŸš€ é«˜çº§ç‰ˆæœ¬ï¼šæ›´ç²¾ç»†çš„æ¦‚ç‡æ§åˆ¶
    
    Args:
        bias_factor: åæ¯”åå‘å› å­ï¼Œè¶Šå¤§åå‘æ€§è¶Šå¼º
        min_prob: æœ€å°æ¦‚ç‡ï¼Œé˜²æ­¢æŸç±»å®Œå…¨è¢«å¿½ç•¥
    """
    
    # åˆ†ç±»å‡½æ•°
    first_turn_tools = []
    other_turn_tools = []
    
    for tool_name, tool_info in first_appearance.items():
        tool_index = tool_info['index']
        
        turn_start_index = None
        for i in range(tool_index, -1, -1):
            if messages[i]['role'] == 'user':
                turn_start_index = i
                break
        
        if turn_start_index is not None:
            if turn_start_index == user_positions[0]:
                first_turn_tools.append(tool_info)
            else:
                other_turn_tools.append(tool_info)
    
    total_first = len(first_turn_tools)
    total_other = len(other_turn_tools)
    
    if total_first == 0:
        return random.choice(other_turn_tools)
    elif total_other == 0:
        if random.random() < 0.2: 
            return random.choice(first_turn_tools)
        return None
    else:
        # ğŸ”¥ é«˜çº§æ¦‚ç‡è®¡ç®—
        # ä½¿ç”¨ bias_factor è°ƒæ•´åæ¯”å¼ºåº¦
        first_turn_weight = (1 / total_first) ** bias_factor
        other_turn_weight = (1 / total_other) ** bias_factor
        
        # å½’ä¸€åŒ–å¹¶åº”ç”¨æœ€å°æ¦‚ç‡çº¦æŸ
        total_weight = first_turn_weight + other_turn_weight
        first_turn_prob = first_turn_weight / total_weight
        
        # åº”ç”¨æœ€å¤§/æœ€å°æ¦‚ç‡çº¦æŸ
        first_turn_prob = max(min_prob, min(max_prob, first_turn_prob))
        
        if random.random() < first_turn_prob:
            return random.choice(first_turn_tools)
        else:
            return random.choice(other_turn_tools)


def _select_tool_with_turn_bias_list(call_list, messages, user_positions, 
                                     bias_factor=2.0, min_prob=0, max_prob=0):
    """
    é€‚é… list ç‰ˆ first_appearance çš„ turn-bias é€‰æ‹©é€»è¾‘ã€‚
    call_list ä¸­çš„å…ƒç´ æ˜¯å®Œæ•´çš„ tool_call ä¿¡æ¯ï¼š
    {'index','tool_name','msg','arguments','required_params','tool_def'}
    """
    first_turn_calls = []
    other_turn_calls = []

    for call in call_list:
        tool_index = call['index']

        turn_start_index = None
        for i in range(tool_index, -1, -1):
            if messages[i]['role'] == 'user':
                turn_start_index = i
                break

        if turn_start_index is not None:
            if turn_start_index == user_positions[0]:
                first_turn_calls.append(call)
            else:
                other_turn_calls.append(call)

    total_first = len(first_turn_calls)
    total_other = len(other_turn_calls)

    if total_first == 0 and total_other == 0:
        return None
    if total_first == 0:
        return random.choice(other_turn_calls)
    elif total_other == 0:
        if random.random() < 0:
            return random.choice(first_turn_calls)
        return None
    else:
        first_turn_weight = (1 / total_first) ** bias_factor
        other_turn_weight = (1 / total_other) ** bias_factor

        total_weight = first_turn_weight + other_turn_weight
        first_turn_prob = first_turn_weight / total_weight

        first_turn_prob = max(min_prob, min(max_prob, first_turn_prob))

        if random.random() < first_turn_prob:
            return random.choice(first_turn_calls)
        else:
            return random.choice(other_turn_calls)

def _select_tool_with_turn_bias_list_plus(call_list, messages, user_positions, 
                                         turn_probs=None, default_prob=0.0, seed=None):
    """
    å¢å¼ºç‰ˆï¼šå¯ä»¥åˆ†åˆ«æ§åˆ¶å‰5ä¸ªè½®æ¬¡çš„æŠ½æ ·æ¦‚ç‡
    
    Args:
        call_list: tool_call åˆ—è¡¨ï¼Œå…ƒç´ æ ¼å¼ï¼š{'index','tool_name','msg','arguments','required_params','tool_def'}
        messages: æ¶ˆæ¯åˆ—è¡¨
        user_positions: useræ¶ˆæ¯çš„ä½ç½®åˆ—è¡¨
        turn_probs: è½®æ¬¡æŠ½æ ·æ¦‚ç‡é…ç½®ï¼Œå¯ä»¥æ˜¯ï¼š
            - dict: {1: 0.3, 2: 0.2, 3: 0.15, 4: 0.1, 5: 0.05} è¡¨ç¤ºå„è½®æ¬¡çš„æŠ½æ ·æ¦‚ç‡
            - list: [0.3, 0.2, 0.15, 0.1, 0.05] è¡¨ç¤ºç¬¬1-5è½®çš„æ¦‚ç‡ï¼ˆç´¢å¼•0å¯¹åº”ç¬¬1è½®ï¼‰
        default_prob: ç¬¬6è½®åŠä»¥åçš„é»˜è®¤æŠ½æ ·æ¦‚ç‡ï¼ˆé»˜è®¤0.0ï¼Œå³ä¸æŠ½æ ·ï¼‰
        seed: éšæœºç§å­
    
    Returns:
        é€‰ä¸­çš„tool_callï¼Œå¦‚æœæ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„åˆ™è¿”å›None
    """
    if seed is not None:
        random.seed(seed)
    
    # è§£æturn_probså‚æ•°
    if turn_probs is None:
        # é»˜è®¤é…ç½®ï¼šç¬¬1è½®æ¦‚ç‡è¾ƒé«˜ï¼Œåç»­é€’å‡
        turn_probs = {1: 0.1, 2: 0.4, 3: 0.2, 4: 0.1, 5: 0.05}
    
    if isinstance(turn_probs, list):
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸
        turn_probs = {i+1: prob for i, prob in enumerate(turn_probs) if i < 5}
    
    # ç¡®ä¿turn_probsæ˜¯å­—å…¸æ ¼å¼
    if not isinstance(turn_probs, dict):
        turn_probs = {}
    
    # æŒ‰è½®æ¬¡åˆ†ç»„
    turn_groups = {}  # {turn_number: [calls]}
    
    for call in call_list:
        tool_index = call['index']
        
        # æ‰¾åˆ°è¿™ä¸ªtool_callå±äºå“ªä¸ªè½®æ¬¡
        turn_start_index = None
        for i in range(tool_index, -1, -1):
            if messages[i]['role'] == 'user':
                turn_start_index = i
                break
        
        if turn_start_index is not None:
            # ç¡®å®šè¿™æ˜¯ç¬¬å‡ è½®ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰
            try:
                turn_number = user_positions.index(turn_start_index) + 1
            except ValueError:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè·³è¿‡
                continue
            
            if turn_number not in turn_groups:
                turn_groups[turn_number] = []
            turn_groups[turn_number].append(call)
    
    if not turn_groups:
        return None
    
    # è®¡ç®—æ¯ä¸ªè½®æ¬¡çš„æƒé‡ï¼ˆåŸºäºæ¦‚ç‡å’Œæ•°é‡ï¼‰
    turn_weights = {}
    for turn_num, calls in turn_groups.items():
        count = len(calls)
        if count == 0:
            continue
        
        # è·å–è¯¥è½®æ¬¡çš„æŠ½æ ·æ¦‚ç‡
        prob = turn_probs.get(turn_num, default_prob if turn_num > 5 else 0.0)
        
        # å¦‚æœæ¦‚ç‡ä¸º0ï¼Œè·³è¿‡è¯¥è½®æ¬¡
        if prob <= 0:
            continue
        
        # æƒé‡è®¡ç®—æ–¹å¼ï¼š
        # æ–¹å¼1: prob / count - æ•°é‡è¶Šå°‘ï¼Œæƒé‡è¶Šé«˜ï¼ˆåå‘æ ·æœ¬å°‘çš„è½®æ¬¡ï¼‰
        # æ–¹å¼2: prob * count - æ•°é‡è¶Šå¤šï¼Œæƒé‡è¶Šé«˜ï¼ˆåå‘æ ·æœ¬å¤šçš„è½®æ¬¡ï¼‰
        # æ–¹å¼3: prob - ç›´æ¥ä½¿ç”¨æ¦‚ç‡ï¼Œä¸è€ƒè™‘æ•°é‡
        # è¿™é‡Œä½¿ç”¨æ–¹å¼1ï¼Œå› ä¸ºé€šå¸¸æˆ‘ä»¬å¸Œæœ›å¹³è¡¡å„è½®æ¬¡çš„æ ·æœ¬åˆ†å¸ƒ
        turn_weights[turn_num] = prob 
    
    if not turn_weights:
        return None
    
    # å½’ä¸€åŒ–æƒé‡
    total_weight = sum(turn_weights.values())
    if total_weight == 0:
        return None
    
    # æ ¹æ®æƒé‡è¿›è¡ŒåŠ æƒéšæœºé€‰æ‹©
    rand_val = random.random() * total_weight
    cumulative = 0
    
    for turn_num, weight in sorted(turn_weights.items()):
        cumulative += weight
        if rand_val <= cumulative:
            # ä»è¯¥è½®æ¬¡ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
            return random.choice(turn_groups[turn_num])
    
    # å¦‚æœç”±äºæµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜æ²¡æœ‰é€‰ä¸­ï¼Œè¿”å›æƒé‡æœ€å¤§çš„è½®æ¬¡ä¸­çš„ä¸€ä¸ª
    max_turn = max(turn_weights.items(), key=lambda x: x[1])[0]
    return random.choice(turn_groups[max_turn])

def process_single_sample_v3(data):
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ï¼ŒåŸºäºè½®æ¬¡åˆ†å¸ƒçš„åŠ¨æ€æ¦‚ç‡æŠ½æ ·
    æ”¹è¿›ç­–ç•¥ï¼š
    1. æŒ‰ç¬¬ä¸€è½®å’Œå…¶ä»–è½®åˆ†ç±»
    2. ä½¿ç”¨åæ¯”å…³ç³»åŠ¨æ€è°ƒæ•´æŠ½æ ·æ¦‚ç‡
    3. åŸºäºuser message indexåˆ‡åˆ†åçš„æ¦‚ç‡åˆ†å¸ƒ
    """
    
    if data['subset_name'] not in ['multi-turn','single-turn-original']:
        return data

    messages = data['messages']
    assert type(messages) == str
    messages = json.loads(messages)
    assert type(messages) == list
    # 0. å…ˆæ”¶é›†æ‰€æœ‰ user message çš„ä½ç½®ï¼Œç”¨äºç¡®å®šè½®æ¬¡
    user_positions = []
    for i, msg in enumerate(messages):
        if msg['role'] == 'user':
            user_positions.append(i)
    if not user_positions:
        return data
    # 1. æ‰¾åˆ°æ¯ä¸ªå‡½æ•°ç¬¬ä¸€æ¬¡å‡ºç°çš„ä½ç½®
    first_appearance = {}
    for i, msg in enumerate(messages):
        if msg['role'] == 'tool_call':
            try:
                tool_info = json.loads(msg['content'])
                tool_name = tool_info.get('name')
                if tool_name and tool_name not in first_appearance:
                    first_appearance[tool_name] = {
                        'index': i,
                        'tool_name': tool_name,
                        'msg': msg
                    }
            except:
                try:
                    tool_info = ast.literal_eval(msg['content'])
                    tool_name = tool_info.get('name')
                    if tool_name and tool_name not in first_appearance:
                        first_appearance[tool_name] = {
                            'index': i,
                            'tool_name': tool_name,
                            'msg': msg
                        }
                except:
                    assert 0
    if not first_appearance:
        return data
    # ğŸš€ **æ ¸å¿ƒæ”¹è¿›ï¼šåŸºäºè½®æ¬¡åˆ†å¸ƒçš„åŠ¨æ€æ¦‚ç‡æŠ½æ ·**
    # åŸºäºsub-category é€‰æ‹©é‡‡æ ·ç­–ç•¥
    selected_tool_info = None
    if data['subset_name'] == 'multi-turn':
        if random.random() < 0:
            selected_tool_info = _select_tool_with_turn_bias(
                first_appearance, messages, user_positions
            )
    elif data['subset_name'] in ['single-turn-original']:
        if random.random() < 0:
            selected_tool_info = random.choice(list(first_appearance.values())) 
        else:
            selected_tool_info = None
    if not selected_tool_info:
        return data
    selected_tool_name = selected_tool_info['tool_name']
    selected_tool_index = selected_tool_info['index']
    # åç»­å¤„ç†é€»è¾‘ä¿æŒä¸å˜...
    # 3. å¾€å‰æ‰¾åˆ°ç¦»è¿™ä¸ªå‡½æ•°æœ€è¿‘çš„user messageçš„index
    selected_turn_start = None
    for i in range(selected_tool_index, -1, -1):
        if messages[i]['role'] == 'user':
            selected_turn_start = i
            break
    if selected_turn_start is None:
        return data
    # ç¡®å®šè¿™æ˜¯ç¬¬å‡ è½®
    turn_number = user_positions.index(selected_turn_start)
    # 4. ç¡®å®šturnç»“æŸä½ç½®
    turn_end = len(messages)
    for i in range(selected_turn_start + 1, len(messages)):
        if messages[i]['role'] == 'user':
            turn_end = i
            break
    # 5. å¤„ç†toolsä¿¡æ¯
    tools_list = json.loads(data['tools'])
    removed_tool = None
    new_tools_list = []
    for tool in tools_list:
        if tool.get('type') == 'function' and tool['function']['name'] == selected_tool_name:
            removed_tool = tool
        else:
            new_tools_list.append(tool)
    if removed_tool is None:
        return data
    # æ·»åŠ å…ƒä¿¡æ¯
    data['is_modified'] = True
    data['modification_info'] = json.dumps({
        'modified_turn_index': selected_turn_start,
        'turn_number': turn_number,
        'total_turns': len(user_positions),
        'removed_tool_name': selected_tool_name,
        'removed_tool_definition': removed_tool,
        'selection_method': 'turn_biased',  # æ ‡è®°ä½¿ç”¨äº†æ–°çš„é€‰æ‹©æ–¹æ³•
    }, ensure_ascii=False)
    # æ›´æ–°toolså­—æ®µ
    data['tools'] = json.dumps(new_tools_list, ensure_ascii=False)
    # 6. æ„é€ æ–°æ¶ˆæ¯åºåˆ—
    original_user_msg = messages[selected_turn_start]
    new_messages = []
    # ä¿ç•™ä¹‹å‰çš„æ¶ˆæ¯
    new_messages.extend(messages[:selected_turn_start])
    # æ·»åŠ ç¬¬ä¸€ä¸ªturn
    new_messages.append(copy.deepcopy(original_user_msg))
    new_messages.append({
        'role': 'assistant',
        'content': "Sorry, I don't have enough information to answer the request. I'm missing some necessary tools to complete this task."
    })
    # æ·»åŠ ç¬¬äºŒä¸ªturn
    tool_info_message = {
        'role': 'user',
        'content': f"Here is the additional tool you can use now: {json.dumps(removed_tool, ensure_ascii=False)}"
    }
    new_messages.append(tool_info_message)
    new_messages.extend(messages[selected_turn_start + 1:turn_end])
    new_messages.extend(messages[turn_end:])
    data['messages'] = json.dumps(new_messages, ensure_ascii=False)
    return data
def analyze_modified_samples(modified_samples):
    """
    ç»Ÿè®¡ä¿®æ”¹æ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯

    Args:
        modified_samples: è¢«ä¿®æ”¹çš„æ ·æœ¬æ•°æ®é›†

    Returns:
        dict: åŒ…å«å„ç§ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    from collections import Counter

    stats = {
        'total_modified': len(modified_samples),
        'turn_number_distribution': Counter(),  # æ¯ä¸ªè½®æ¬¡è¢«ä¿®æ”¹çš„æ¬¡æ•°
        'removed_tools': Counter(),  # è¢«ç§»é™¤çš„å·¥å…·åç§°åŠå…¶æ¬¡æ•°
        'total_turns_distribution': Counter(),  # æ ·æœ¬æ€»è½®æ¬¡çš„åˆ†å¸ƒ
        'turn_percentage_distribution': [],  # ä¿®æ”¹å‘ç”Ÿåœ¨æ ·æœ¬ä¸­çš„ç›¸å¯¹ä½ç½®ï¼ˆç™¾åˆ†æ¯”ï¼‰
        'function_call_count_distribution': Counter(),  # æ¯ä¸ªæ ·æœ¬çš„function callæ•°é‡åˆ†å¸ƒ
    }

    for sample in modified_samples:
        if sample['is_modified'] and sample['modification_info'] and sample['subset_name'] in ['multi-turn','single-turn-original']:
            try:
                mod_info = json.loads(sample['modification_info'])

                # ç»Ÿè®¡è½®æ¬¡åˆ†å¸ƒ
                turn_number = mod_info.get('turn_number', -1)
                stats['turn_number_distribution'][turn_number] += 1

                # ç»Ÿè®¡è¢«ç§»é™¤çš„å·¥å…·
                removed_tool_name = mod_info.get('removed_tool_name', 'unknown')
                stats['removed_tools'][removed_tool_name] += 1

                # ç»Ÿè®¡æ€»è½®æ¬¡åˆ†å¸ƒ
                total_turns = mod_info.get('total_turns', 0)
                stats['total_turns_distribution'][total_turns] += 1

                # è®¡ç®—ä¿®æ”¹å‘ç”Ÿçš„ç›¸å¯¹ä½ç½®ï¼ˆç™¾åˆ†æ¯”ï¼‰
                if total_turns > 0:
                    percentage = (turn_number / total_turns) * 100
                    stats['turn_percentage_distribution'].append(percentage)

                # ç»Ÿè®¡æ ·æœ¬æœ‰å¤šå°‘ä¸ªfunction call
                messages = sample.get('messages', '[]')
                if isinstance(messages, str):
                    messages = json.loads(messages)

                function_call_count = sum(1 for msg in messages if msg.get('role') == 'tool_call')
                stats['function_call_count_distribution'][function_call_count] += 1

            except json.JSONDecodeError:
                continue

    return stats



def print_statistics(stats):
    """
    æ‰“å°ç»Ÿè®¡ä¿¡æ¯

    Args:
        stats: analyze_modified_samplesè¿”å›çš„ç»Ÿè®¡å­—å…¸
    """
    print("\n" + "="*60)
    print("Modified Samples Statistics")
    print("="*60)

    print(f"\nğŸ“Š Total modified samples: {stats['total_modified']}")

    # æ‰“å°è½®æ¬¡åˆ†å¸ƒ
    print("\nğŸ”¢ Turn Number Distribution (which turn was modified):")
    turn_numbers = sorted(stats['turn_number_distribution'].items())
    for turn_num, count in turn_numbers:
        percentage = (count / stats['total_modified']) * 100
        print(f"  Turn {turn_num}: {count} samples ({percentage:.2f}%)")

    # æ‰“å°æ€»è½®æ¬¡åˆ†å¸ƒ
    print("\nğŸ“ˆ Total Turns Distribution (how many turns in sample):")
    total_turns = sorted(stats['total_turns_distribution'].items())
    for turns, count in total_turns:
        percentage = (count / stats['total_modified']) * 100
        print(f"  {turns} turns: {count} samples ({percentage:.2f}%)")

    # æ‰“å°è¢«ç§»é™¤å·¥å…·çš„ç»Ÿè®¡ï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªï¼‰
    print("\nğŸ”§ Top 20 Removed Tools:")
    top_tools = stats['removed_tools'].most_common(20)
    for tool_name, count in top_tools:
        percentage = (count / stats['total_modified']) * 100
        print(f"  {tool_name}: {count} times ({percentage:.2f}%)")

    # æ‰“å°function callæ•°é‡åˆ†å¸ƒ
    print("\nğŸ“ Function Call Count Distribution:")
    function_call_counts = sorted(stats['function_call_count_distribution'].items())

    # è®¡ç®—å¹³å‡function callæ•°é‡
    total_function_calls = sum(count * samples for count, samples in function_call_counts)
    avg_function_calls = total_function_calls / stats['total_modified'] if stats['total_modified'] > 0 else 0
    print(f"  Average function calls per sample: {avg_function_calls:.2f}")
    print()

    for count, samples in function_call_counts:
        percentage = (samples / stats['total_modified']) * 100
        print(f"  {count} function calls: {samples} samples ({percentage:.2f}%)")

    # æ‰“å°ç›¸å¯¹ä½ç½®ç»Ÿè®¡
    if stats['turn_percentage_distribution']:
        import statistics
        percentages = stats['turn_percentage_distribution']
        print("\nğŸ“ Modification Position (as percentage of total turns):")
        print(f"  Mean: {statistics.mean(percentages):.2f}%")
        print(f"  Median: {statistics.median(percentages):.2f}%")
        print(f"  Min: {min(percentages):.2f}%")
        print(f"  Max: {max(percentages):.2f}%")

        # åˆ†æ®µç»Ÿè®¡
        early = sum(1 for p in percentages if p < 33.33)
        middle = sum(1 for p in percentages if 33.33 <= p < 66.67)
        late = sum(1 for p in percentages if p >= 66.67)
        total = len(percentages)

        print(f"\n  Early turns (0-33%): {early} ({early/total*100:.2f}%)")
        print(f"  Middle turns (33-67%): {middle} ({middle/total*100:.2f}%)")
        print(f"  Late turns (67-100%): {late} ({late/total*100:.2f}%)")

    print("\n" + "="*60 + "\n")

def filter_by_ratio(dataset, field_name, target_value, remove_ratio=0.5):
    """
    æŒ‰æ¯”ä¾‹å‰”é™¤åŒ¹é…çš„æ•°æ®
    remove_ratio: 0.0-1.0ï¼Œè¡¨ç¤ºå‰”é™¤åŒ¹é…æ•°æ®çš„æ¯”ä¾‹
    """
    import random
    
    def ratio_filter(example, idx):
        if example[field_name] == target_value:
            # æ ¹æ®ç´¢å¼•å’Œæ¯”ä¾‹å†³å®šæ˜¯å¦ä¿ç•™
            random.seed(idx)  # ç¡®ä¿ç»“æœå¯é‡ç°
            return random.random() > remove_ratio
        return True
    
    return dataset.filter(ratio_filter, with_indices=True)

def filter_by_turn_number_with_sampling(dataset, turn_number=1, max_count=None, sampling_ratio=None, seed=42):
    """
    æŒ‰ç…§turn_numberå¯¹æ•°æ®é›†è¿›è¡Œè¿‡æ»¤å’ŒæŠ½æ ·
    
    Args:
        dataset: æ•°æ®é›†ï¼Œæ¯ä¸ªæ ·æœ¬çš„modification_infoå­—æ®µåŒ…å«turn_numberä¿¡æ¯
        turn_number: è¦æ§åˆ¶çš„turn_numberå€¼ï¼ˆé»˜è®¤ä¸º1ï¼‰
        max_count: å¯¹äºæŒ‡å®šturn_numberçš„æ ·æœ¬ï¼Œæœ€å¤šä¿ç•™çš„æ•°é‡ï¼ˆNoneè¡¨ç¤ºä¸é™åˆ¶ï¼‰
        sampling_ratio: å¯¹äºæŒ‡å®šturn_numberçš„æ ·æœ¬ï¼Œä¿ç•™çš„æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶ï¼‰
                       max_countå’Œsampling_ratioåŒæ—¶æŒ‡å®šæ—¶ï¼Œä¼˜å…ˆä½¿ç”¨max_count
        seed: éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°
    
    Returns:
        filtered_dataset: è¿‡æ»¤åçš„æ•°æ®é›†
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    from collections import Counter
    import random
    
    random.seed(seed)
    
    # å…ˆæŒ‰turn_numberåˆ†ç»„
    turn_number_samples = []  # æŒ‡å®šturn_numberçš„æ ·æœ¬
    other_samples = []  # å…¶ä»–turn_numberçš„æ ·æœ¬
    
    for sample in dataset:
        try:
            if sample.get('modification_info'):
                mod_info = json.loads(sample['modification_info'])
                sample_turn_number = mod_info.get('turn_number')
                
                if sample_turn_number == turn_number:
                    turn_number_samples.append(sample)
                else:
                    other_samples.append(sample)
            else:
                # å¦‚æœæ²¡æœ‰modification_infoï¼Œä¿ç•™
                other_samples.append(sample)
        except (json.JSONDecodeError, TypeError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œä¿ç•™
            other_samples.append(sample)
    
    # å¯¹æŒ‡å®šturn_numberçš„æ ·æœ¬è¿›è¡ŒæŠ½æ ·
    original_count = len(turn_number_samples)
    
    if max_count is not None:
        # ä½¿ç”¨max_counté™åˆ¶æ•°é‡
        if len(turn_number_samples) > max_count:
            # éšæœºæŠ½æ ·
            turn_number_samples = random.sample(turn_number_samples, max_count)
            print(f"Sampled {max_count} samples from {original_count} samples with turn_number={turn_number}")
        else:
            print(f"All {original_count} samples with turn_number={turn_number} are kept (requested {max_count})")
    elif sampling_ratio is not None:
        # ä½¿ç”¨sampling_ratioé™åˆ¶æ¯”ä¾‹
        target_count = int(len(turn_number_samples) * sampling_ratio)
        if target_count < len(turn_number_samples):
            turn_number_samples = random.sample(turn_number_samples, target_count)
            print(f"Sampled {target_count} samples ({sampling_ratio*100:.1f}%) from {original_count} samples with turn_number={turn_number}")
        else:
            print(f"All {original_count} samples with turn_number={turn_number} are kept (requested {sampling_ratio*100:.1f}%)")
    else:
        print(f"All {original_count} samples with turn_number={turn_number} are kept (no sampling)")
    
    # åˆå¹¶ç»“æœ
    filtered_samples = turn_number_samples + other_samples
    
    # ç»Ÿè®¡ä¿¡æ¯
    turn_number_distribution = Counter()
    for sample in filtered_samples:
        try:
            if sample.get('modification_info'):
                mod_info = json.loads(sample['modification_info'])
                sample_turn_number = mod_info.get('turn_number')
                if sample_turn_number is not None:
                    turn_number_distribution[sample_turn_number] += 1
        except (json.JSONDecodeError, TypeError):
            pass
    
    stats = {
        'original_total': len(dataset),
        'filtered_total': len(filtered_samples),
        'turn_number_distribution': turn_number_distribution,
        'target_turn_number': turn_number,
        'target_turn_original_count': original_count,
        'target_turn_filtered_count': len(turn_number_samples),
    }
    
    # å°†åˆ—è¡¨è½¬æ¢å›æ•°æ®é›†
    # ä½¿ç”¨datasetsåº“çš„Dataset.from_listæ–¹æ³•
    filtered_dataset = datasets.Dataset.from_list(filtered_samples)
    
    return filtered_dataset, stats

def init_single_sample(data):
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ï¼ŒåŸºäºè½®æ¬¡åˆ†å¸ƒçš„åŠ¨æ€æ¦‚ç‡æŠ½æ ·
    æ”¹è¿›ç­–ç•¥ï¼š
    1. æŒ‰ç¬¬ä¸€è½®å’Œå…¶ä»–è½®åˆ†ç±»
    2. ä½¿ç”¨åæ¯”å…³ç³»åŠ¨æ€è°ƒæ•´æŠ½æ ·æ¦‚ç‡
    3. åŸºäºuser message indexåˆ‡åˆ†åçš„æ¦‚ç‡åˆ†å¸ƒ
    """
    # åˆå§‹åŒ–æ–°å­—æ®µ
    data['is_modified'] = False
    data['modification_info'] = ""
    
    return data

def shuffle_sample_tool_list(data):
    """
    shuffle the tool list
    """
    tools_list = json.loads(data['tools'])
    random.shuffle(tools_list)
    data['tools'] = json.dumps(tools_list, ensure_ascii=False)
    return data

def extract_processed_uuids(dataset):
    """
    ä»æ•°æ®é›†ä¸­æå–æ‰€æœ‰ modified æ ·æœ¬çš„ uuidã€‚
    è¿™äº› uuid å¯¹åº”çš„åŸå§‹æ ·æœ¬ï¼ˆis_modified == Falseï¼‰ä¸åº”è¯¥å†æ¬¡è¢«å¤„ç†ã€‚
    
    Args:
        dataset: æ•°æ®é›†
    
    Returns:
        set: å·²å¤„ç†çš„ uuid é›†åˆ
    """
    processed_uuids = set()
    
    for sample in dataset:
        if sample.get('is_modified', False) and 'uuid' in sample:
            processed_uuids.add(sample['uuid'])
    
    return processed_uuids

def find_common_uuids(dataset1, dataset2, dataset1_name="Dataset1", dataset2_name="Dataset2"):
    """
    æŸ¥æ‰¾ä¸¤ä¸ªæ•°æ®é›†ä¸­uuidç›¸åŒçš„æ ·æœ¬
    
    Args:
        dataset1: ç¬¬ä¸€ä¸ªæ•°æ®é›†
        dataset2: ç¬¬äºŒä¸ªæ•°æ®é›†
        dataset1_name: ç¬¬ä¸€ä¸ªæ•°æ®é›†çš„åç§°ï¼ˆç”¨äºæ‰“å°ï¼‰
        dataset2_name: ç¬¬äºŒä¸ªæ•°æ®é›†çš„åç§°ï¼ˆç”¨äºæ‰“å°ï¼‰
    
    Returns:
        dict: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
            - common_uuids: ä¸¤ä¸ªæ•°æ®é›†ä¸­ç›¸åŒçš„uuidé›†åˆ
            - dataset1_uuids: ç¬¬ä¸€ä¸ªæ•°æ®é›†ä¸­çš„æ‰€æœ‰uuidé›†åˆ
            - dataset2_uuids: ç¬¬äºŒä¸ªæ•°æ®é›†ä¸­çš„æ‰€æœ‰uuidé›†åˆ
            - dataset1_only: åªåœ¨ç¬¬ä¸€ä¸ªæ•°æ®é›†ä¸­å­˜åœ¨çš„uuidé›†åˆ
            - dataset2_only: åªåœ¨ç¬¬äºŒä¸ªæ•°æ®é›†ä¸­å­˜åœ¨çš„uuidé›†åˆ
            - stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    # æå–ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„æ‰€æœ‰uuid
    dataset1_uuids = set()
    dataset2_uuids = set()
    
    for sample in dataset1:
        if 'uuid' in sample and sample['uuid']:
            dataset1_uuids.add(sample['uuid'])
    
    for sample in dataset2:
        if 'uuid' in sample and sample['uuid']:
            dataset2_uuids.add(sample['uuid'])
    
    # æ‰¾å‡ºç›¸åŒçš„uuid
    common_uuids = dataset1_uuids & dataset2_uuids
    
    # æ‰¾å‡ºåªåœ¨å„è‡ªæ•°æ®é›†ä¸­å­˜åœ¨çš„uuid
    dataset1_only = dataset1_uuids - dataset2_uuids
    dataset2_only = dataset2_uuids - dataset1_uuids
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'dataset1_total': len(dataset1),
        'dataset2_total': len(dataset2),
        'dataset1_uuids_count': len(dataset1_uuids),
        'dataset2_uuids_count': len(dataset2_uuids),
        'common_uuids_count': len(common_uuids),
        'dataset1_only_count': len(dataset1_only),
        'dataset2_only_count': len(dataset2_only),
    }
    
    return {
        'common_uuids': common_uuids,
        'dataset1_uuids': dataset1_uuids,
        'dataset2_uuids': dataset2_uuids,
        'dataset1_only': dataset1_only,
        'dataset2_only': dataset2_only,
        'stats': stats,
    }

def print_common_uuids_info(common_info, dataset1_name="Dataset1", dataset2_name="Dataset2"):
    """
    æ‰“å°ä¸¤ä¸ªæ•°æ®é›†uuidæ¯”è¾ƒçš„ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        common_info: find_common_uuidsè¿”å›çš„å­—å…¸
        dataset1_name: ç¬¬ä¸€ä¸ªæ•°æ®é›†çš„åç§°
        dataset2_name: ç¬¬äºŒä¸ªæ•°æ®é›†çš„åç§°
    """
    stats = common_info['stats']
    
    print("\n" + "="*60)
    print(f"UUID Comparison: {dataset1_name} vs {dataset2_name}")
    print("="*60)
    
    print(f"\nğŸ“Š Dataset Statistics:")
    print(f"  {dataset1_name}:")
    print(f"    Total samples: {stats['dataset1_total']}")
    print(f"    Samples with uuid: {stats['dataset1_uuids_count']}")
    print(f"  {dataset2_name}:")
    print(f"    Total samples: {stats['dataset2_total']}")
    print(f"    Samples with uuid: {stats['dataset2_uuids_count']}")
    
    print(f"\nğŸ” Comparison Results:")
    print(f"  Common uuids: {stats['common_uuids_count']}")
    if stats['dataset1_uuids_count'] > 0:
        common_percentage_1 = (stats['common_uuids_count'] / stats['dataset1_uuids_count']) * 100
        print(f"    ({common_percentage_1:.2f}% of {dataset1_name} samples)")
    if stats['dataset2_uuids_count'] > 0:
        common_percentage_2 = (stats['common_uuids_count'] / stats['dataset2_uuids_count']) * 100
        print(f"    ({common_percentage_2:.2f}% of {dataset2_name} samples)")
    
    print(f"  Only in {dataset1_name}: {stats['dataset1_only_count']}")
    print(f"  Only in {dataset2_name}: {stats['dataset2_only_count']}")
    
    # å¦‚æœç›¸åŒçš„uuidæ•°é‡è¾ƒå°‘ï¼Œå¯ä»¥æ‰“å°å‡ºæ¥
    if stats['common_uuids_count'] > 0 and stats['common_uuids_count'] <= 50:
        print(f"\nğŸ“‹ Common UUIDs (showing all {stats['common_uuids_count']}):")
        for uuid in sorted(common_info['common_uuids']):
            print(f"    {uuid}")
    elif stats['common_uuids_count'] > 50:
        print(f"\nğŸ“‹ Common UUIDs (showing first 20 of {stats['common_uuids_count']}):")
        for uuid in sorted(list(common_info['common_uuids']))[:20]:
            print(f"    {uuid}")
        print(f"    ... and {stats['common_uuids_count'] - 20} more")
    
    print("\n" + "="*60 + "\n")

def remove_common_uuids_from_dataset(dataset1, dataset2):
    """
    ä»dataset1ä¸­ç§»é™¤ä¸dataset2æœ‰ç›¸åŒUUIDçš„æ ·æœ¬
    
    Args:
        dataset1: ç¬¬ä¸€ä¸ªæ•°æ®é›†ï¼ˆéœ€è¦è¢«è¿‡æ»¤çš„æ•°æ®é›†ï¼‰
        dataset2: ç¬¬äºŒä¸ªæ•°æ®é›†ï¼ˆç”¨äºæ¯”è¾ƒçš„æ•°æ®é›†ï¼‰
    
    Returns:
        tuple: (filtered_dataset, removed_count, common_uuids)
            - filtered_dataset: è¿‡æ»¤åçš„æ•°æ®é›†
            - removed_count: è¢«ç§»é™¤çš„æ ·æœ¬æ•°é‡
            - common_uuids: é‡åˆçš„UUIDé›†åˆ
    """
    # é¦–å…ˆæ‰¾å‡ºä¸¤ä¸ªæ•°æ®é›†ä¸­ç›¸åŒçš„UUID
    common_info = find_common_uuids(dataset1, dataset2)
    common_uuids = common_info['common_uuids']
    
    if not common_uuids:
        print("No common UUIDs found. Returning original dataset1.")
        return dataset1, 0, common_uuids
    
    print(f"Found {len(common_uuids)} common UUIDs. Filtering dataset1...")
    
    # è¿‡æ»¤dataset1ï¼Œç§»é™¤UUIDåœ¨common_uuidsä¸­çš„æ ·æœ¬
    def filter_func(example):
        if 'uuid' in example and example['uuid']:
            return example['uuid'] not in common_uuids
        # å¦‚æœæ²¡æœ‰uuidå­—æ®µï¼Œä¿ç•™è¯¥æ ·æœ¬
        return True
    
    filtered_dataset = dataset1.filter(filter_func)
    removed_count = len(dataset1) - len(filtered_dataset)
    
    print(f"Removed {removed_count} samples from dataset1.")
    print(f"Original dataset1 size: {len(dataset1)}")
    print(f"Filtered dataset1 size: {len(filtered_dataset)}")
    
    return filtered_dataset, removed_count, common_uuids

def process_single_sample_v4(data, processed_uuids=None):
    """
    this function is used to process sample to miss param situation.
    random sample one function call(fc A) need have params in tool_call step in one random select turn.
    find the before and after nearest user message index(index_b,index_c) ,we copy this turn at the begining of the index_b, and å…¶ä½™çš„indexä¾æ¬¡å‘å, then we get needed to rewrite user message and target tool, then we can based on
    the target tool call required func param to rewrite user message to contruct the lack param info turn. 
    
    Args:
        data: æ•°æ®é›†æ ·æœ¬
        processed_uuids: set, å·²å¤„ç†çš„ uuid é›†åˆï¼Œç”¨äºé¿å…é‡å¤å¤„ç†åŒä¸€åŸå§‹æ ·æœ¬
    """
    
    # ä»…å¤„ç† subset_name åœ¨ç›®æ ‡é›†åˆä¸­ï¼Œä¸”å½“å‰è¿˜æœªè¢«æ ‡è®°ä¿®æ”¹çš„æ•°æ®
    # å³ï¼šsubset_name in ['multi-turn','single-turn-original'] ä¸” data['is_modified'] == False
    if data['subset_name'] not in ['multi-turn'] or data.get('is_modified', False):
        return data
    
    # æ£€æŸ¥å½“å‰æ ·æœ¬çš„ uuid æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆå³å­˜åœ¨ç›¸åŒ uuid ä¸” is_modified == True çš„æ ·æœ¬ï¼‰
    if processed_uuids is not None and 'uuid' in data:
        if data['uuid'] in processed_uuids:
            # è¿™ä¸ªåŸå§‹æ ·æœ¬å·²ç»è¢«ç”¨æ¥ç”Ÿæˆè¿‡ modified æ ·æœ¬äº†ï¼Œè·³è¿‡
            return data

    messages = data['messages']
    assert type(messages) == str
    messages = json.loads(messages)
    assert type(messages) == list
    # 0. å…ˆæ”¶é›†æ‰€æœ‰ user message çš„ä½ç½®ï¼Œç”¨äºç¡®å®šè½®æ¬¡
    user_positions = []
    for i, msg in enumerate(messages):
        if msg['role'] == 'user':
            user_positions.append(i)
    if not user_positions:
        return data
    # 1. collect tool call index set with full param info
    #    first_appearance åœ¨è¿™é‡Œè¡¨ç¤ºâ€œæ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„ tool_call é›†åˆâ€ï¼Œå…ƒç´ æ˜¯å®Œæ•´çš„è°ƒç”¨ä¿¡æ¯
    tools_list = json.loads(data['tools'])
    tools_dict = {}
    for tool in tools_list:
        if tool.get('type') == 'function':
            tools_dict[tool['function']['name']] = tool

    first_appearance = []  # list of call_info: {'index','tool_name','msg','arguments','required_params','tool_def'}
    for i, msg in enumerate(messages):
        if msg['role'] != 'tool_call':
            continue

        # è§£æ tool_call å†…å®¹
        try:
            tool_info = json.loads(msg['content'])
        except Exception:
            try:
                tool_info = ast.literal_eval(msg['content'])
            except Exception:
                continue

        if not isinstance(tool_info, dict):
            continue

        tool_name = tool_info.get('name')
        tool_args = tool_info.get('arguments', {})

        # judge tool_arge type
        assert type(tool_args) == str
        try:
            tool_args = json.loads(tool_args)
        except Exception:
            continue
        if type(tool_args) == str:
            tool_args = json.loads(tool_args)
        assert type(tool_args) == dict
        # è¦æ±‚ï¼šæœ‰å‚æ•°ä¸”ä¸º dictï¼Œä¸”éç©º
        if not (tool_name and isinstance(tool_args, dict) and tool_args):
            continue

        # æ ¹æ® schema æ£€æŸ¥ required å‚æ•°æ˜¯å¦éƒ½åœ¨ arguments ä¸­
        tool_def = tools_dict.get(tool_name)
        if not tool_def:
            continue

        required_params = tool_def.get('function', {}).get('parameters', {}).get('required', [])
        # å¦‚æœ schema æ²¡æœ‰ required æˆ– required ä¸ºç©ºï¼Œåˆ™è®¤ä¸ºä¸æ»¡è¶³â€œç¼ºå‚æ•°â€ä»»åŠ¡çš„å‰æï¼Œç›´æ¥è·³è¿‡
        if not required_params:
            continue

        if not all(req in tool_args for req in required_params):
            # å‚æ•°æ²¡æœ‰å®Œå…¨è¦†ç›– requiredï¼Œå°±è·³è¿‡
            continue

        call_info = {
            'index': i,
            'tool_name': tool_name,
            'msg': msg,
            'arguments': tool_args,
            'required_params': required_params,
            'tool_def': tool_def,
        }

        # ä¿è¯é›†åˆä¸­ä¸å‡ºç°å®Œå…¨ç›¸åŒçš„è°ƒç”¨ï¼ˆåŒå + ç›¸åŒå‚æ•°ï¼‰
        if not any(
            c['tool_name'] == call_info['tool_name'] and c['arguments'] == call_info['arguments']
            for c in first_appearance
        ):
            first_appearance.append(call_info)

    if not first_appearance:
        return data

    # 2. åœ¨ first_appearance(list) ä¸­åšåŸºäºè½®æ¬¡çš„åç½®é‡‡æ ·
    selected_tool_info = None
    if data['subset_name'] == 'multi-turn':
        if random.random() < 0.5:
            # æ–¹å¼1: ä½¿ç”¨åŸå§‹ç‰ˆæœ¬ï¼ˆåªåŒºåˆ†first turnå’Œother turnï¼‰
            # selected_tool_info = _select_tool_with_turn_bias_list(
            #     first_appearance, messages, user_positions
            # )
            
            # æ–¹å¼2: ä½¿ç”¨å¢å¼ºç‰ˆï¼ˆå¯ä»¥åˆ†åˆ«æ§åˆ¶å‰5ä¸ªè½®æ¬¡çš„æ¦‚ç‡ï¼‰
            # é…ç½®ç¤ºä¾‹ï¼šç¬¬1è½®30%ï¼Œç¬¬2è½®20%ï¼Œç¬¬3è½®15%ï¼Œç¬¬4è½®10%ï¼Œç¬¬5è½®5%ï¼Œå…¶ä»–è½®æ¬¡ä¸æŠ½æ ·
            turn_probs = {
                1: 0,   # ç¬¬1è½®æŠ½æ ·æ¦‚ç‡
                2: 0.2,   # ç¬¬2è½®æŠ½æ ·æ¦‚ç‡
                3: 0.4,  # ç¬¬3è½®æŠ½æ ·æ¦‚ç‡
                4: 0.6,   # ç¬¬4è½®æŠ½æ ·æ¦‚ç‡
                5: 0.8,  # ç¬¬5è½®æŠ½æ ·æ¦‚ç‡
            }
            # æˆ–è€…ä½¿ç”¨åˆ—è¡¨æ ¼å¼ï¼š[0.3, 0.2, 0.15, 0.1, 0.05]
            # turn_probs = [0.3, 0.2, 0.15, 0.1, 0.05]
            
            selected_tool_info = _select_tool_with_turn_bias_list_plus(
                first_appearance, 
                messages, 
                user_positions,
                turn_probs=turn_probs,
                default_prob=0,  # ç¬¬6è½®åŠä»¥åçš„é»˜è®¤æ¦‚ç‡ï¼ˆ0.0è¡¨ç¤ºä¸æŠ½æ ·ï¼‰
                seed=42  # å¯ä»¥è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°
            )
    elif data['subset_name'] in ['single-turn-original']:
        if random.random() < 0.3:
            selected_tool_info = random.choice(first_appearance)
        else:
            selected_tool_info = None
    if not selected_tool_info:
        return data

    selected_tool_name = selected_tool_info['tool_name']
    selected_tool_index = selected_tool_info['index']

    # 2. è§£æé€‰ä¸­ tool_call çš„å‚æ•°ï¼Œç”¨äº miss-param å…ƒä¿¡æ¯
    tool_call_args = selected_tool_info['arguments']
    
    

    # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œå°±ä¸æ„é€  miss-param åœºæ™¯
    if not isinstance(tool_call_args, dict) or not tool_call_args:
        return data

    # 3. å¾€å‰æ‰¾åˆ°ç¦»è¿™ä¸ªå‡½æ•°æœ€è¿‘çš„user messageçš„index
    selected_turn_start = None
    for i in range(selected_tool_index, -1, -1):
        if messages[i]['role'] == 'user':
            selected_turn_start = i
            break
    if selected_turn_start is None:
        return data

    # ç¡®å®šè¿™æ˜¯ç¬¬å‡ è½®
    turn_number = user_positions.index(selected_turn_start)

    # 4. ç¡®å®šturnç»“æŸä½ç½®
    turn_end = len(messages)
    for i in range(selected_turn_start + 1, len(messages)):
        if messages[i]['role'] == 'user':
            turn_end = i
            break

    # 5. å¤„ç†toolsä¿¡æ¯ï¼ˆä¿æŒä¸åŸé€»è¾‘ä¸€è‡´ï¼‰
    tools_list = json.loads(data['tools'])
    target_tool_def = None

    for tool in tools_list:
        if tool.get('type') == 'function' and tool['function']['name'] == selected_tool_name:
            target_tool_def = tool

    if target_tool_def is None:
        return data

    # æ·»åŠ å…ƒä¿¡æ¯ï¼Œè¡¥å…… target tool call çš„å‚æ•°ä¿¡æ¯
    base_mod_info = {}
    if data.get('modification_info'):
        try:
            base_mod_info = json.loads(data['modification_info'])
        except Exception:
            base_mod_info = {}
    
    base_mod_info.update({
        'modified_type': 'miss-param',
        'modified_turn_index': selected_turn_start,
        'turn_number': turn_number,
        'total_turns': len(user_positions),
        'target_tool_name': selected_tool_name,
        'target_tool_definition': target_tool_def,
        'selection_method': 'turn_biased',  # æ ‡è®°ä½¿ç”¨äº†æ–°çš„é€‰æ‹©æ–¹æ³•
        'target_tool_call_arguments': tool_call_args,
        'target_tool_call_index': selected_tool_index,
    })

    data['is_modified'] = True
    data['modification_info'] = json.dumps(base_mod_info, ensure_ascii=False)


    # # 6. æ„é€ æ–°æ¶ˆæ¯åºåˆ—ï¼ˆå¤ç”¨åŸé€»è¾‘ï¼Œåªåœ¨ç¬¬äºŒä¸ª turn ä½¿ç”¨ raw user messageï¼‰
    # original_user_msg = messages[selected_turn_start]
    # new_messages = []
    # # ä¿ç•™ä¹‹å‰çš„æ¶ˆæ¯
    # new_messages.extend(messages[:selected_turn_start])
    # # æ·»åŠ ç¬¬ä¸€ä¸ªturnï¼šåŸå§‹ user + ç¼ºä¿¡æ¯çš„ assistant
    # new_messages.append(copy.deepcopy(original_user_msg))
    # new_messages.append({
    #     'role': 'assistant',
    #     'content': "Sorry, I don't have enough information to answer the request. I'm missing some necessary parameters to complete this task."
    # })
    # # æ·»åŠ ç¬¬äºŒä¸ªturnï¼šä½¿ç”¨ raw user messageï¼Œè€Œä¸æ˜¯å·¥å…·è¯´æ˜åŒ…è£…
    # new_messages.append(copy.deepcopy(original_user_msg))

    # # æ·»åŠ åŸturnä¸­é™¤äº†æœ€åˆ user æ¶ˆæ¯ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆassistant å›å¤ã€tool_call ç­‰ï¼‰
    # new_messages.extend(messages[selected_turn_start + 1:turn_end])
    # # æ·»åŠ è¿™ä¸ªturnä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
    # new_messages.extend(messages[turn_end:])

    # data['messages'] = json.dumps(new_messages, ensure_ascii=False)
    return data

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # æ£€æŸ¥ä¸¤ä¸ªæ•°æ®é›†çš„UUIDé‡åˆæƒ…å†µï¼Œåˆ†æmiss func å’Œ miss param
    # ç„¶åæ‰¾åˆ°é‡åˆçš„UUID,æŠŠdatasets1 ä¹Ÿå°±æ˜¯miss paramé‡Œçš„æ•°æ®å‰”æ‰
    # dataset1 = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/multi-turn-miss-param-v4')
    # dataset2 = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v1/multi-turn-miss-func-subset')
    
    # # å…ˆæŸ¥çœ‹é‡åˆæƒ…å†µ
    # stats = find_common_uuids(dataset1, dataset2, "miss-param", "miss-func")
    # print_common_uuids_info(stats, "miss-param", "miss-func")
    
    # # ä»dataset1ä¸­ç§»é™¤ä¸dataset2æœ‰ç›¸åŒUUIDçš„æ ·æœ¬
    # filtered_dataset1, removed_count, common_uuids = remove_common_uuids_from_dataset(
    #     dataset1, dataset2
    # )
    
    # # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
    # filtered_dataset1.save_to_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/multi-turn-miss-param-v2-filtered')
    # print(f"Filtered dataset saved successfully!")
    
    #assert 0
    # åˆ†æturns,
    # from datasets import concatenate_datasets
    # dataset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/multi-turn-miss-param-v2-filtered')
    # dataset1 = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/multi-turn-miss-param-v4')
    # total_dataset = concatenate_datasets([dataset,dataset1])

    # stats = analyze_modified_samples(total_dataset)
    # print_statistics(stats)
    # assert 0
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯å¤ç°æ€§
    random.seed(42)

    # åŠ è½½æ•°æ®é›†
    dataset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v1/total')
    #dataset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/totalv3')
    print(f"Original dataset size: {len(dataset)}")
    
    raw_count = sum(1 for sample in dataset if sample.get('is_modified') is not None)
    print(f"Raw modify sample: {raw_count}")

    # filtered_dataset = dataset.shuffle(seed=42).select(range(1740))
    # filtered_dataset.save_to_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/single-turn-miss-param-subset-1740')
    # assert 0
    # step 0: è¿‡æ»¤éƒ¨åˆ†subset == irrelevantæ•°æ®
    filtered_dataset = filter_by_ratio(dataset,'subset_name','irrelevant',1)
    filtered_dataset = filtered_dataset.filter(lambda x: not x['is_modified'])
    #filtered_dataset = filtered_dataset.map(init_single_sample)
    #filtered_dataset = filtered_dataset.map(shuffle_sample_tool_list)
    print(f"Original samples: {len(dataset)}")
    print(f"filtered samples: {len(filtered_dataset)}")
    
    # Step 0.5: æå–å·²å¤„ç†çš„ uuidï¼Œé¿å…é‡å¤å¤„ç†åŒä¸€åŸå§‹æ ·æœ¬
    print("Step 0.5: Extracting processed uuids...")
    processed_uuids = extract_processed_uuids(filtered_dataset)
    
    # Step 0.8: æå–å·²å¤„ç†çš„ä¸€æ‰¹æ ·æœ¬çš„uuid(ä¸€ä¸ªæ–°çš„dataset),æ·»åŠ åˆ°processed_uuidsé‡Œ
    print("Step 0.8: Extracting processed uuids from additional datasets...")
    additional_datasets = [
        '/data/lhy/datasets/1202/Toucan-SFT-v3/multi-turn-miss-param-v2-filtered',
        '/data/lhy/datasets/1202/Toucan-SFT-v1/multi-turn-miss-func-subset',
        '/data/lhy/datasets/1202/Toucan-SFT-v1/single-turn-miss-func-subset'
        # å¯ä»¥æ·»åŠ æ›´å¤šæ•°æ®é›†è·¯å¾„
    ]
    
    for dataset_path in additional_datasets:
        try:
            additional_dataset = datasets.load_from_disk(dataset_path)
            additional_uuids = extract_processed_uuids(additional_dataset)
            processed_uuids.update(additional_uuids)
            print(f"  Loaded {len(additional_uuids)} uuids from {dataset_path}")
        except Exception as e:
            print(f"  Warning: Failed to load dataset from {dataset_path}: {e}")
    
    print(f"Found {len(processed_uuids)} already-processed original samples (by uuid)")
    
    #Step 1: å¤„ç†æ•°æ®é›†ï¼Œç”Ÿæˆå¢å¼ºæ ·æœ¬
    print("Step 1: Processing samples to create augmented data...")
    # ä½¿ç”¨é—­åŒ…ä¼ é€’ processed_uuids
    def process_with_uuids(data):
        return process_single_sample_v4(data, processed_uuids=processed_uuids)
    
    augmented_dataset = filtered_dataset.map(process_with_uuids)

    #augmented_dataset = filtered_dataset
    #Step 2: ç­›é€‰å‡ºè¢«ä¿®æ”¹çš„æ ·æœ¬ï¼ˆè¿™äº›æ˜¯å¢å¼ºæ•°æ®ï¼‰
    # print("Step 2: Filtering modified samples...")
    
    # modified_samples = augmented_dataset.filter(lambda x:  x['is_modified']  and json.loads(x['modification_info']).get('modified_type') == 'miss-param' and x['subset_name'] == 'multi-turn')

    # # ç»Ÿè®¡å¤„ç†ç»“æœ
    # print(f"augmented samples: {len(augmented_dataset)}")
    # print(f"modified samples: {len(modified_samples)}")

    # #ç»Ÿè®¡ä¿®æ”¹çš„æ ·æœ¬å’Œä¿®æ”¹çš„turnä¿¡æ¯
    # print("\nAnalyzing modified samples...")
    # stats = analyze_modified_samples(modified_samples)
    # print_statistics(stats)

    # modified_samplesæˆ‘éœ€è¦æŒ‰ç…§å­—æ®µmodification_infoçš„turn_numberè¿›è¡Œfilterï¼Œæˆ‘æƒ³è‡ªç”±æ§åˆ¶turn_number==1çš„æ•°é‡ï¼Œä¹Ÿå°±æ˜¯å†æŠ½æ ·ä¸€ä¸ªå­é›†
    #print("\nFiltering modified_samples by turn_number...")
    # æ–¹å¼1: ä½¿ç”¨max_countæ§åˆ¶turn_number==1çš„æ•°é‡ï¼ˆä¾‹å¦‚æœ€å¤šä¿ç•™500ä¸ªï¼‰
    # modified_samples, filter_stats = filter_by_turn_number_with_sampling(
    #     modified_samples, 
    #     turn_number=1, 
    #     max_count=5000,  # æœ€å¤šä¿ç•™500ä¸ªturn_number==1çš„æ ·æœ¬
    #     seed=42
    # )
    
    # æ–¹å¼2: ä½¿ç”¨sampling_ratioæ§åˆ¶turn_number==1çš„æ¯”ä¾‹ï¼ˆä¾‹å¦‚ä¿ç•™50%ï¼‰
    # modified_samples, filter_stats = filter_by_turn_number_with_sampling(
    #     modified_samples, 
    #     turn_number=1, 
    #     sampling_ratio=0.5,  # ä¿ç•™50%çš„turn_number==1çš„æ ·æœ¬
    #     seed=42
    # )
    
    # æ–¹å¼3: ä¸è¿›è¡ŒæŠ½æ ·ï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬
    # modified_samples, filter_stats = filter_by_turn_number_with_sampling(
    #     modified_samples, 
    #     turn_number=1
    # )
    
    # æ‰“å°è¿‡æ»¤åçš„ç»Ÿè®¡ä¿¡æ¯
    # print(f"\nFilter Statistics:")
    # print(f"  Original total: {filter_stats['original_total']}")
    # print(f"  Filtered total: {filter_stats['filtered_total']}")
    # print(f"  Turn number distribution: {dict(filter_stats['turn_number_distribution'])}")
    # print(f"  Turn {filter_stats['target_turn_number']} samples: {filter_stats['target_turn_original_count']} -> {filter_stats['target_turn_filtered_count']}")
    
    #Step 3: åˆå¹¶åŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®
    print("Step 3: Concatenating original and augmented data...")
    
    from datasets import concatenate_datasets
    
    # modified_multi_turn_dataset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/multi-turn-miss-param-v8')
    #modified_multi_turn_dataset = modified_multi_turn_dataset.shuffle(seed=42).select(range(1000))
    modified_single_turn_dataset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v3/single-turn-miss-param')
    #modified_single_turn_dataset = modified_single_turn_dataset.shuffle(seed=42).select(range(2500))
    # miss_func_multi_turn_subset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v1/multi-turn-miss-func-subset')
    miss_func_single_turn_subset = datasets.load_from_disk('/data/lhy/datasets/1202/Toucan-SFT-v1/single-turn')
    
    #final_dataset = concatenate_datasets([modified_multi_turn_dataset, modified_single_turn_dataset,filtered_dataset])
    final_dataset = concatenate_datasets([modified_single_turn_dataset,filtered_dataset,miss_func_single_turn_subset])
    #final_dataset = modified_samples
    final_dataset = final_dataset.map(shuffle_sample_tool_list)
    #final_dataset = concatenate_datasets([filtered_dataset, modified_samples])

    print(f"Final dataset size: {len(final_dataset)}")

    #Step 4: fix æ•°æ®æ ¼å¼
    print("Step 4: Checking and fixing format...")
    formated_dataset = final_dataset.map(check_and_fix_format)

    print("Format check completed!")
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®é›†
    formated_dataset.save_to_disk('/data/lhy/datasets/1211/Toucan-SFT')
    print("Dataset saved successfully!")
